# üóÑÔ∏è STRUCTURE DES TABLES - Vue Compl√®te

**Date de cr√©ation** : 13 octobre 2025  
**Derni√®re mise √† jour** : 13 octobre 2025 12:45 UTC  
**Version** : 1.0  
**Status** : ‚úÖ **DOCUMENT√â** - 930,394 documents, 9.5 GB total

---

## üéØ Vue d'Ensemble

Ce document d√©crit la structure compl√®te des tables Supabase utilis√©es par ArchiReg, leur r√¥le, leurs colonnes, et leurs tailles.

---

## üìä Flux de Donn√©es Complet

```mermaid
graph TD
    A[Microservice L√©gifrance PISTE] -->|Upload JSON| B[Bucket Supabase Storage]
    B -->|Insertion| C[files_queue<br/>1,118,025 fichiers<br/>553 MB]
    
    C -->|WorkerLocal x3| D[parsed_files<br/>930,950 historique<br/>580 MB]
    
    D -->|Parse + Embedding| E[documents<br/>930,394 docs<br/>8,243 MB]
    
    E -->|Index HNSW| F[idx_documents_embedding_hnsw<br/>199 MB<br/>‚è≥ EN CONSTRUCTION]
    
    E -.->|Futur| G[document_chunks<br/>0 chunks<br/>3.6 MB]
    
    G -.->|Index HNSW| H[idx_document_chunks_embedding_hnsw<br/>16 kB<br/>‚úÖ ACTIF]
    
    E -->|RAG Search| I[Backend Agent-Orchestrator]
    I -->|Context| J[Chatbot Frontend]
    
    K[Frontend Chat] -->|Messages| L[chat_messages<br/>620 messages<br/>4.6 MB]
    L -->|Group√©s| M[conversations<br/>2 convos<br/>104 kB]
    
    style E fill:#4CAF50
    style F fill:#FFC107
    style I fill:#2196F3
```

---

## üìã Tables Principales

### 1Ô∏è‚É£ `documents` - C≈íUR DU SYST√àME RAG

**R√¥le** : Stocke les documents juridiques L√©gifrance avec leurs embeddings pour la recherche s√©mantique.

**Statistiques** :
- **Rows** : 930,394 documents
- **Taille table** : 504 MB (donn√©es brutes)
- **Taille index** : 4,021 MB (dont 199 MB HNSW en construction)
- **TOTAL** : 8,243 MB

**Colonnes principales** :

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `id` | uuid | Identifiant unique | `a1b2c3d4-...` |
| `title` | text | Titre du document | "Code de l'urbanisme - Article L151-1" |
| `content` | text | Texte complet juridique | "Le plan local d'urbanisme..." |
| `summary` | text | R√©sum√© (nullable) | "D√©finition du PLU..." |
| `embedding` | vector(768) | Vecteur GGUF Solon Base | `[0.123, -0.456, ...]` |
| `metadata` | jsonb | M√©tadonn√©es (vide) | `{}` |
| `extra_data` | jsonb | M√©tadonn√©es Workers | `{"source": "workerlocal"}` |
| `file_path` | text | Chemin bucket Supabase | `batch_001/doc_123.json` |
| `upload_date` | timestamptz | Date d'upload | `2025-10-12 15:30:00+00` |

**Index** :
- ‚úÖ `PRIMARY KEY (id)` : B-tree
- ‚úÖ `UNIQUE (file_path)` : B-tree
- ‚è≥ `idx_documents_embedding_hnsw` : **HNSW (en construction)** - 199 MB

**Utilisation** :
- Workers : INSERT apr√®s g√©n√©ration embedding
- Backend : SELECT avec recherche vectorielle (`embedding <=> query::vector`)
- Frontend : Lecture via Backend (jamais direct)

---

### 2Ô∏è‚É£ `files_queue` - QUEUE DE TRAITEMENT

**R√¥le** : File d'attente pour le traitement des fichiers JSON upload√©s par le microservice L√©gifrance.

**Statistiques** :
- **Rows** : 1,118,025 fichiers
- **Taille table** : 218 MB
- **Taille index** : 335 MB
- **TOTAL** : 553 MB

**Colonnes principales** :

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `id` | bigint | ID s√©quentiel (pagination) | `1`, `2`, `3`... |
| `file_path` | text | Chemin bucket Supabase | `batch_001/doc_123.json` |
| `bucket_id` | text | Nom du bucket | `agentbasic-legifrance-raw` |
| `file_size` | bigint | Taille en bytes | `12345` |
| `processed` | boolean | Fichier trait√© ? | `true`/`false` |
| `processed_at` | timestamptz | Date traitement | `2025-10-12 15:30:00+00` |
| `worker_id` | text | Worker qui a trait√© | `worker-local-1` |
| `status` | text | √âtat actuel | `pending`, `processing`, `completed`, `failed` |

**Index** :
- ‚úÖ `PRIMARY KEY (id)` : B-tree (pagination efficace)
- ‚úÖ `UNIQUE (file_path)` : B-tree (√©vite doublons)

**Utilisation** :
- Microservice : INSERT apr√®s upload bucket
- Workers : SELECT WHERE processed = false ORDER BY id LIMIT 1000
- Backend : Lecture stats via Edge Function `admin-stats`

**Progression** : 930k/1.1M trait√©s = **83.2% compl√©t√©**

---

### 3Ô∏è‚É£ `parsed_files` - HISTORIQUE PARSING

**R√¥le** : Trace l'historique de tous les fichiers pars√©s par les Workers.

**Statistiques** :
- **Rows** : 930,950 fichiers
- **Taille table** : 208 MB
- **Taille index** : 372 MB
- **TOTAL** : 580 MB

**Colonnes principales** :

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `id` | uuid | Identifiant unique | `a1b2c3d4-...` |
| `file_path` | text | Chemin bucket (unique) | `batch_001/doc_123.json` |
| `legifrance_id` | text | ID L√©gifrance (nullable) | `LEGIARTI000006417896` |
| `content_hash` | text | Hash MD5 du contenu | `a1b2c3d4e5f6...` |
| `parsed_at` | timestamptz | Date parsing | `2025-10-12 15:30:00+00` |
| `status` | text | √âtat parsing | `processing`, `completed`, `failed` |
| `worker_id` | text | Worker responsable | `worker-local-1` |

**Index** :
- ‚úÖ `PRIMARY KEY (id)` : B-tree
- ‚úÖ `UNIQUE (file_path)` : B-tree (√©vite double parsing)

**Utilisation** :
- Workers : INSERT apr√®s parsing r√©ussi
- Backend : V√©rifier si fichier d√©j√† pars√© avant traitement
- Admin : Stats historiques

---

### 4Ô∏è‚É£ `document_chunks` - CHUNKING GRANULAIRE (FUTUR)

**R√¥le** : Stockera les chunks granulaires avec embeddings pour recherche fine.

**Statistiques** :
- **Rows** : 0 (vide, futur WorkerLocal Chunk)
- **Taille table** : 0 bytes
- **Taille index** : 3,648 kB (16 kB HNSW)
- **TOTAL** : 3.6 MB

**Colonnes principales** :

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `id` | uuid | Identifiant unique | `a1b2c3d4-...` |
| `document_id` | uuid | Lien vers documents.id | `uuid-parent` |
| `chunk_index` | int | Position chunk (0, 1, 2...) | `0` |
| `content` | text | Contenu chunk (500-1000 chars) | "Article L151-1..." |
| `embedding` | vector(768) | Vecteur GGUF chunk | `[0.123, -0.456, ...]` |
| `metadata` | jsonb | M√©tadonn√©es chunk | `{"section": "Article"}` |

**Index** :
- ‚úÖ `PRIMARY KEY (id)` : B-tree
- ‚úÖ `idx_document_chunks_embedding_hnsw` : **HNSW (ACTIF)** - 16 kB

**Utilisation future** :
- WorkerLocal Chunk : INSERT chunks + embeddings
- Backend : Recherche fine avec RAG multi-niveaux (doc entier + chunks)

---

### 5Ô∏è‚É£ `chat_messages` - HISTORIQUE CONVERSATIONNEL

**R√¥le** : Stocke l'historique complet des conversations utilisateur ‚Üî assistant.

**Statistiques** :
- **Rows** : 620 messages
- **Taille table** : 2,008 kB
- **Taille index** : 1,088 kB
- **TOTAL** : 4.6 MB

**Colonnes principales** :

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `id` | uuid | Identifiant unique | `a1b2c3d4-...` |
| `user_id` | uuid | Utilisateur propri√©taire | `uuid-user` |
| `conversation_id` | uuid | Lien conversation | `uuid-convo` |
| `message` | text | Contenu message | "Code de l'urbanisme" |
| `role` | text | R√¥le (user/assistant/system) | `user` |
| `model_used` | text | Mod√®le LLM utilis√© | `openai/gpt-oss-120b` |
| `tokens_used` | int | Tokens consomm√©s | `1234` |
| `response_time_ms` | int | Temps r√©ponse | `3500` |
| `metadata` | jsonb | M√©tadonn√©es diverses | `{"rag_docs": 3}` |

**Index** :
- ‚úÖ `PRIMARY KEY (id)` : B-tree
- ‚úÖ Foreign Keys : `user_id`, `conversation_id`

**Utilisation** :
- Frontend : INSERT apr√®s chaque message
- Backend : SELECT pour contexte conversation
- Admin : Stats usage LLM

---

## üìä Autres Tables Importantes

### `conversations`
- **Rows** : 2
- **Taille** : 104 kB
- **R√¥le** : Grouper les messages par conversation
- **Colonnes** : id, user_id, project_id, title, message_count, total_tokens

### `projects`
- **Rows** : 0 (vide)
- **Taille** : 88 kB
- **R√¥le** : Gestion projets architecture (futur)
- **Colonnes** : id, name, address, plu_zone, building_permit_required

### `users`
- **Rows** : 0 (vide)
- **Taille** : 64 kB
- **R√¥le** : Authentification utilisateurs
- **Colonnes** : id, email, username, subscription_tier, api_usage_count

### `ingestion_metrics`
- **Rows** : 13,653
- **Taille** : 2 MB
- **R√¥le** : M√©triques workers (batch, temps traitement)
- **Colonnes** : id, worker_id, batch_id, processed_files, processing_time_ms

### `system_alerts`
- **Rows** : 242
- **Taille** : 120 kB
- **R√¥le** : Alertes syst√®me (erreurs, warnings)
- **Colonnes** : id, alert_type, severity, message, resolved

---

## üîç Index HNSW - √âtat Actuel (13 oct 2025)

### `idx_documents_embedding_hnsw`

**√âtat** : ‚è≥ **EN CONSTRUCTION**

```json
{
  "index_name": "idx_documents_embedding_hnsw",
  "current_size": "199 MB",
  "is_valid": false,
  "is_ready": false,
  "total_rows": 930701,
  "status": "‚è≥ EN CONSTRUCTION - Encore quelques minutes",
  "time_elapsed": "49 minutes",
  "estimated_remaining": "5-10 minutes"
}
```

**Phases de Construction** :

```
Phase 1: Scan initial (lecture s√©quentielle)      [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 80% compl√©t√©
Phase 2: Build HNSW graph (construction graphe)   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 60% ‚Üê ACTUEL
Phase 3: Finalisation (optimisation connexions)   [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%
Phase 4: Validation (activation index)            [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%
```

**Quand `is_valid = true` :**
- ‚úÖ PostgreSQL utilisera l'index automatiquement
- ‚úÖ Recherche <1s sur 930k docs
- ‚úÖ Chatbot instantan√© avec RAG complet

### `idx_document_chunks_embedding_hnsw`

**√âtat** : ‚úÖ **ACTIF**

```json
{
  "index_name": "idx_document_chunks_embedding_hnsw",
  "current_size": "16 kB",
  "is_valid": true,
  "is_ready": true,
  "total_rows": 0,
  "status": "‚úÖ ACTIF - Pr√™t pour chunks futurs"
}
```

---

## üìà Statistiques Globales

### Donn√©es RAG

| Table | Documents | Taille | Index HNSW | Status |
|-------|-----------|--------|------------|--------|
| `documents` | 930,394 | 504 MB | 199 MB | ‚è≥ En construction |
| `document_chunks` | 0 | 0 bytes | 16 kB | ‚úÖ Actif |

### Progression Ingestion

| M√©trique | Valeur | Taux |
|----------|--------|------|
| **Fichiers queue** | 1,118,025 | 100% |
| **Fichiers pars√©s** | 930,950 | 83.2% |
| **Documents RAG** | 930,394 | 83.2% |
| **Restants** | 187,075 | 16.8% |

### Utilisation Espace

| Cat√©gorie | Taille | Pourcentage |
|-----------|--------|-------------|
| **Table documents** | 504 MB | 5.3% |
| **Index documents** | 4,021 MB | 42.3% |
| **Table files_queue** | 218 MB | 2.3% |
| **Index files_queue** | 335 MB | 3.5% |
| **Table parsed_files** | 208 MB | 2.2% |
| **Index parsed_files** | 372 MB | 3.9% |
| **Autres tables** | ~3,842 MB | 40.5% |
| **TOTAL DATABASE** | **~9,500 MB** | **100%** |

---

## üîÑ Workflow Complet

### 1. Collecte (Microservice L√©gifrance)

```
Microservice PISTE
  ‚Üí Upload JSON vers bucket Supabase Storage
  ‚Üí INSERT INTO files_queue (file_path, bucket_id, status='pending')
```

### 2. Parsing (WorkerLocal x3)

```
WorkerLocal
  ‚Üí SELECT FROM files_queue WHERE processed = false ORDER BY id LIMIT 1000
  ‚Üí Parse JSON + G√©n√©ration embedding GGUF
  ‚Üí INSERT INTO documents (title, content, embedding, extra_data)
  ‚Üí INSERT INTO parsed_files (file_path, status='completed')
  ‚Üí UPDATE files_queue SET processed = true, status='completed'
```

### 3. Recherche S√©mantique (Backend)

```
Frontend
  ‚Üí POST /api/v3/chat/completions {"message": "Code urbanisme"}
  
Backend Orchestrator
  ‚Üí G√©n√®re embedding query avec GGUF
  ‚Üí SELECT FROM documents 
     WHERE embedding <=> query::vector < 0.3
     ORDER BY distance
     LIMIT 8
     (Utilise index HNSW quand is_valid = true)
  ‚Üí Retourne top 8 documents similaires
  ‚Üí Injecte contexte dans prompt LLM
  ‚Üí Stream r√©ponse vers frontend
```

### 4. Chunking Futur (WorkerLocal Chunk)

```
WorkerLocal Chunk (pas encore actif)
  ‚Üí SELECT FROM documents WHERE non chunk√©
  ‚Üí D√©coupe en chunks 500-1000 chars
  ‚Üí G√©n√®re embedding par chunk
  ‚Üí INSERT INTO document_chunks (document_id, chunk_index, content, embedding)
```

---

## üéØ Tables par Cat√©gorie

### üìö RAG & Embeddings

| Table | Rows | Taille | R√¥le |
|-------|------|--------|------|
| `documents` | 930,394 | 8,243 MB | Documents + embeddings contexte |
| `document_chunks` | 0 | 3.6 MB | Chunks + embeddings granulaires (futur) |

### üì• Ingestion & Queue

| Table | Rows | Taille | R√¥le |
|-------|------|--------|------|
| `files_queue` | 1,118,025 | 553 MB | Queue traitement fichiers |
| `parsed_files` | 930,950 | 580 MB | Historique parsing |

### üí¨ Chat & Utilisateurs

| Table | Rows | Taille | R√¥le |
|-------|------|--------|------|
| `chat_messages` | 620 | 4.6 MB | Messages chat |
| `conversations` | 2 | 104 kB | Groupement conversations |
| `users` | 0 | 64 kB | Authentification |

### üèóÔ∏è Projets Architecture

| Table | Rows | Taille | R√¥le |
|-------|------|--------|------|
| `projects` | 0 | 88 kB | Projets architecture (futur) |
| `templates` | 0 | 64 kB | Templates documents (futur) |

### üìä Monitoring & M√©triques

| Table | Rows | Taille | R√¥le |
|-------|------|--------|------|
| `ingestion_metrics` | 13,653 | 2 MB | M√©triques workers |
| `system_alerts` | 242 | 120 kB | Alertes syst√®me |
| `timeline_cache` | 17 | 72 kB | Cache timeline 24h |
| `realtime_metrics` | 1 | 32 kB | Compteurs temps r√©el |

---

## ‚ö° Optimisations Appliqu√©es

### Index HNSW (13 oct 2025)

**Objectif** : Acc√©l√©rer recherche vectorielle de 30s+ ‚Üí <1s

**Index cr√©√©s** :
```sql
-- documents.embedding (930k docs)
CREATE INDEX CONCURRENTLY idx_documents_embedding_hnsw 
ON documents USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- document_chunks.embedding (futur)
CREATE INDEX CONCURRENTLY idx_document_chunks_embedding_hnsw 
ON document_chunks USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

**√âtat actuel** :
- ‚è≥ `idx_documents_embedding_hnsw` : EN CONSTRUCTION (199 MB, ~60-70% fait)
- ‚úÖ `idx_document_chunks_embedding_hnsw` : ACTIF (16 kB)

**Gains attendus** :
- Temps : 30s+ ‚Üí <1s (**100x-1000x**)
- Calculs : 930,000 ‚Üí ~150 (**6,200x**)
- Coverage : 21% ‚Üí 100% (**479%**)

---

## üîß Commandes Utiles

### V√©rifier l'√©tat des index HNSW

```sql
SELECT 
    i.relname as index_name,
    pg_size_pretty(pg_relation_size(i.oid)) as size,
    idx.indisvalid as is_valid,
    idx.indisready as is_ready
FROM pg_class i
JOIN pg_index idx ON i.oid = idx.indexrelid
WHERE i.relname LIKE '%hnsw%';
```

### Statistiques des tables principales

```sql
SELECT 
    tablename,
    pg_size_pretty(pg_total_relation_size('public.'||tablename)) as total_size,
    (SELECT reltuples::bigint FROM pg_class WHERE relname = tablename) as estimated_rows
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size('public.'||tablename) DESC
LIMIT 10;
```

### Progression ingestion

```sql
SELECT 
    COUNT(*) FILTER (WHERE processed = true) as completed,
    COUNT(*) FILTER (WHERE processed = false) as pending,
    COUNT(*) as total,
    ROUND(100.0 * COUNT(*) FILTER (WHERE processed = true) / COUNT(*), 2) as pct_done
FROM files_queue;
```

---

## üìö R√©f√©rences

- [PostgreSQL pg_class](https://www.postgresql.org/docs/current/catalog-pg-class.html)
- [PostgreSQL pg_index](https://www.postgresql.org/docs/current/catalog-pg-index.html)
- [pgvector HNSW](https://github.com/pgvector/pgvector#hnsw)
- [CREATE INDEX CONCURRENTLY](https://www.postgresql.org/docs/current/sql-createindex.html#SQL-CREATEINDEX-CONCURRENTLY)

---

**üéØ R√âSUM√â** : 17 tables, 930k documents RAG, 9.5 GB, index HNSW en construction (5-10 min restantes)

