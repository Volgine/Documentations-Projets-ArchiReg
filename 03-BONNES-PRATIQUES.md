# üìñ BONNES PRATIQUES & POINTS CRITIQUES

**Date** : 11 octobre 2025  
**Version** : 1.0  
**Status** : ‚úÖ **GUIDE COMPLET**

---

## üéØ Introduction

Ce document regroupe les **bonnes pratiques**, **pi√®ges √† √©viter**, et **points critiques** pour maintenir et faire √©voluer ArchiReg.

---

## üö® POINTS CRITIQUES √Ä NE JAMAIS OUBLIER

### **1. n_ctx DOIT √äTRE ALIGN√â AVEC LE MOD√àLE** ‚ö†Ô∏è

**R√àGLE D'OR** :
```python
# ‚úÖ CORRECT
n_ctx = 512  # Align√© avec bert.context_length du mod√®le Solon-base

# ‚ùå INCORRECT
n_ctx = 4096  # ‚Üí Warning "exceeds trained context length" ‚Üí Qualit√© d√©grad√©e
```

**O√π v√©rifier** :
- `WorkerLocal/embedding/llama_service.py` (ligne 63)
- `WorkerLocal Chunk/embedding/llama_service.py` (ligne 63)
- `Agent-Orchestrator/backend/llama_server.py` (ligne 44)

**Validation** :
```bash
# Logs backend - PAS de warning si correct
# ‚ùå BAD: "WARNING llama_context exceeds trained context length"
# ‚úÖ GOOD: Pas de warning
```

---

### **2. NE JAMAIS MODIFIER LES 2 WORKERS EN M√äME TEMPS** ‚ö†Ô∏è

**R√àGLE** : Un seul worker √† la fois en production

**Raison** :
- WorkerLocal et WorkerLocal Chunk utilisent la **m√™me source** (bucket L√©gifrance)
- Si les 2 lanc√©s en m√™me temps : **doublons de traitement**

**Bonne pratique** :
```bash
# ‚úÖ CORRECT: S√©quentiel
1. Lancer WorkerLocal (termin√© ‚Üí 930k docs)
2. Attendre fin compl√®te
3. Lancer WorkerLocal Chunk (6M chunks)

# ‚ùå INCORRECT: Parall√®le sur m√™me source
Terminal 1: WorkerLocal run
Terminal 2: WorkerLocal Chunk run  # ‚ùå Doublon traitement !
```

**Exception** : Lancement parall√®le OK si worker_id diff√©rents (d√©j√† le cas ‚úÖ)

---

### **3. TOUJOURS UTILISER SERVICE_ROLE_KEY POUR LES WORKERS** üîê

**R√àGLE** : Workers = `service_role`, pas `anon_key`

**Raison** :
- RLS sur `documents` et `document_chunks` : `service_role` uniquement pour INSERT
- `anon_key` ‚Üí 403 Forbidden

**Configuration** :
```python
# ‚úÖ CORRECT
supabase_service_role_key: str = Field("eyJhbGciOiJIUzI1NiIs...")  # Service role

# ‚ùå INCORRECT
supabase_anon_key: str = Field("eyJhbGciOiJIUzI1NiIs...")  # Anon ‚Üí RLS refuse INSERT
```

**V√©rification** :
```bash
# Logs worker - Si erreur 403:
# ‚ùå "403 Forbidden" ‚Üí Tu utilises anon_key au lieu de service_role
```

---

### **4. INDEX PGVECTOR OBLIGATOIRE POUR PERFORMANCE** ‚ö°

**R√àGLE** : Toujours cr√©er index pgvector sur colonnes `embedding`

**Pourquoi** :
- Sans index : Recherche O(n) ‚Üí **500ms** pour 6M chunks
- Avec index IVFFlat : Recherche O(log n) ‚Üí **10-30ms**

**Commandes** :
```sql
-- ‚úÖ Documents (d√©j√† fait)
CREATE INDEX idx_documents_embedding 
ON documents 
USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);

-- ‚úÖ Chunks (d√©j√† fait)
CREATE INDEX idx_chunks_embedding 
ON document_chunks 
USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 300);
```

**Validation** :
```sql
-- V√©rifier les index
SELECT indexname, indexdef 
FROM pg_indexes 
WHERE tablename IN ('documents', 'document_chunks');
```

---

### **5. NE PAS REPARSER LES DOCUMENTS D√âJ√Ä TRAIT√âS** ‚ö†Ô∏è

**R√àGLE** : V√©rifier `parsed_files` AVANT de retraiter

**Raison** :
- 930k documents d√©j√† pars√©s avec qualit√© 100%
- Reparser = **14-16h de travail inutile**

**V√©rification** :
```sql
-- V√©rifier si d√©j√† pars√©
SELECT COUNT(*) FROM parsed_files WHERE status = 'completed';
-- R√©sultat: 930,937 (d√©j√† fait ‚úÖ)
```

**Exception** : Si changement de mod√®le GGUF (dimensions diff√©rentes)

---

### **6. WARM-UP OBLIGATOIRE POUR LE BACKEND** üî•

**R√àGLE** : Toujours faire un warm-up du subprocess llama.cpp au d√©marrage

**Pourquoi** :
- Premi√®re requ√™te : 4.45s (subprocess lazy loading)
- Avec warm-up : 500ms

**Impl√©mentation** :
```python
# backend/core/startup.py (ligne 47)
await embedding_service.get_embedding("test warm-up")
```

**Validation** :
```bash
# Logs backend au d√©marrage - Doit afficher:
# ‚úÖ "üî• Warm-up embedding service..."
# ‚úÖ "‚úÖ Embedding service warm et pr√™t (cache initialis√©)"
```

---

### **7. RENDER CPU : D√âSACTIVER AVX2/FMA** üñ•Ô∏è

**R√àGLE** : Compilation llama-cpp-python SANS optimisations AVX/AVX2/FMA

**Raison** :
- CPU Render : AMD EPYC (supporte SSE4, mais pas toutes les instructions AVX2/FMA)
- Avec AVX2/FMA : **SIGILL (rc=-4)** ‚Üí Crash subprocess

**Configuration** :
```dockerfile
# backend/Dockerfile (ligne 70)
ENV CMAKE_ARGS="-DGGML_NATIVE=OFF -DGGML_AVX=OFF -DGGML_AVX2=OFF -DGGML_FMA=OFF"
ENV FORCE_CMAKE=1
```

**Validation** :
```bash
# Logs backend - Si SIGILL:
# ‚ùå "SIGILL D√âTECT√â (rc=-4): Instruction CPU non support√©e"
# ‚úÖ "‚úÖ Subprocess llama.cpp d√©marr√© (PID: ...)"
```

---

### **8. WORKER_MODE = READ_ONLY POUR LE BACKEND** üìñ

**R√àGLE** : Backend ne doit JAMAIS √©crire dans `documents` ou `document_chunks`

**Raison** :
- Backend : READ ONLY (g√©n√®re embeddings queries, recherche pgvector)
- Workers : WRITE ONLY (g√©n√®rent embeddings documents/chunks)
- S√©paration des responsabilit√©s

**Configuration** :
```python
# backend/core/config.py (ligne 89)
worker_mode: str = os.getenv("WORKER_MODE", "read_only")  # ‚úÖ READ_ONLY
```

**Validation** :
```bash
# Logs backend - Si tentative d'√©criture:
# ‚ùå "Worker mode READ_ONLY: √©criture interdite"
```

---

## üéØ BONNES PRATIQUES WORKERS

### **1. Lancement avec --batch-size adapt√©**

**Recommandations** :
```bash
# ‚úÖ Production: Batch 100 (optimal)
python cli.py run --batch-size 100

# ‚úÖ Test: Batch 10 (rapide)
python cli.py run --batch-size 10 --max-batches 1

# ‚ùå √âviter: Batch 1000 (trop lourd)
python cli.py run --batch-size 1000  # RAM satur√©e
```

---

### **2. Monitoring en temps r√©el**

**Commande** :
```bash
# Terminal 1: Worker
cd WorkerLocal
python cli.py run

# Terminal 2: Stats temps r√©el
python cli.py stats  # Affiche progression
```

**Logs √† surveiller** :
```bash
# ‚úÖ Normal
"‚úÖ Batch termin√©: 100 trait√©s, 0 erreurs, 5 doublons (2.1s)"

# ‚ö†Ô∏è Attention
"‚ö†Ô∏è Fichier non trouv√© (404): legifrance/..."  # Normal si fichier supprim√©

# ‚ùå Probl√®me
"‚ùå Erreur DB: ..."  # V√©rifier connexion Supabase
"‚è±Ô∏è Timeout chunk ..."  # R√©duire batch_size ou max_concurrency
```

---

### **3. Gestion des crashes**

**Si crash Worker** :
```bash
# 1. V√©rifier derniers logs
tail -100 worker.log

# 2. V√©rifier √©tat queue
python -c "
from db.supabase_client import get_supabase_client
import asyncio
async def check():
    client = await get_supabase_client()
    stats = await client.get_stats()
    print(stats)
asyncio.run(check())
"

# 3. Relancer (anti-duplication g√®re la reprise)
python cli.py run
```

**Le worker reprend automatiquement** o√π il s'est arr√™t√© (via `files_queue`)

---

### **4. Nettoyage p√©riodique**

**Supprimer logs anciens** :
```bash
# WorkerLocal
rm ultra_turbo.log.* worker.log.*

# WorkerLocal Chunk
rm ultra_turbo.log.* worker.log.*
```

**Vider cache llama.cpp** (si changement mod√®le) :
```bash
rm -rf cache/shared/*.gguf
```

---

## üîê BONNES PRATIQUES S√âCURIT√â

### **1. Ne JAMAIS commit les secrets**

**Fichiers sensibles** :
- `.env` (service_role_key, API keys)
- `venv/` (environnement Python)
- `cache/` (mod√®les GGUF)
- `*.log` (logs avec donn√©es)

**V√©rification** :
```bash
# ‚úÖ .gitignore doit contenir:
.env
venv/
cache/
*.log
```

---

### **2. RLS toujours activ√©es**

**V√©rification** :
```sql
-- Toutes les tables doivent avoir RLS ON
SELECT tablename, rowsecurity 
FROM pg_tables 
WHERE schemaname = 'public' 
AND rowsecurity = false;

-- R√©sultat attendu: 0 rows (toutes ont RLS)
```

---

### **3. Service role uniquement pour workers et backend**

**R√àGLE** : Frontend n'a JAMAIS acc√®s au `service_role_key`

**V√©rification** :
```bash
# ‚úÖ Frontend utilise:
NEXT_PUBLIC_SUPABASE_ANON_KEY=...  # Anon key (RLS appliqu√©es)

# ‚úÖ Backend utilise:
SUPABASE_SERVICE_ROLE_KEY=...  # Service role (bypass RLS)

# ‚ùå JAMAIS dans frontend:
NEXT_PUBLIC_SUPABASE_SERVICE_ROLE_KEY=...  # ‚ùå DANGEREUX !
```

---

## ‚ö° BONNES PRATIQUES PERFORMANCE

### **1. Batch size optimal : 100**

**Pourquoi** :
- Trop petit (10) : Trop d'appels API (latence r√©seau)
- Trop grand (1000) : Saturation RAM + timeout
- **100** : Sweet spot (test√© et valid√©)

---

### **2. Concurrence max : 50**

**Configuration** :
```python
# config/settings.py
max_concurrency: int = Field(50, ...)  # ‚úÖ Optimal
```

**Raison** :
- 50 threads parall√®les : Utilise CPU √† 100%
- Plus de 50 : Overhead asyncio (diminishing returns)

---

### **3. Index pgvector : 100-300 listes**

**R√®gle de calcul** :
```python
# Nombre de listes IVFFlat
lists = sqrt(nombre_de_rows)

# Documents (930k)
lists = sqrt(930000) ‚âà 100  # ‚úÖ

# Chunks (6M)
lists = sqrt(6000000) ‚âà 300  # ‚úÖ
```

**Trade-off** :
- Moins de listes : Recherche plus rapide, moins pr√©cise
- Plus de listes : Recherche plus lente, plus pr√©cise

---

### **4. Timeout adapt√© √† la charge**

**Valeurs recommand√©es** :
```python
download_timeout: int = 30  # ‚úÖ 30s pour bucket Supabase
processing_timeout: int = 30  # ‚úÖ 30s pour embedding GGUF
```

**Ajustement si probl√®me** :
```python
# Si timeouts fr√©quents:
download_timeout: int = 60  # Augmenter
max_concurrency: int = 30   # R√©duire concurrence
```

---

## üóÑÔ∏è BONNES PRATIQUES BASE DE DONN√âES

### **1. Ne JAMAIS supprimer manuellement dans `parsed_files`**

**Raison** :
- `parsed_files` = Anti-duplication
- Suppression ‚Üí Worker va retraiter ‚Üí Doublon dans `documents`

**Exception** : Si vraiment besoin, supprimer aussi dans `documents` :
```sql
-- ‚úÖ Supprimer des 2 tables
DELETE FROM documents WHERE file_path = 'xxx';
DELETE FROM parsed_files WHERE file_path = 'xxx';
```

---

### **2. V√©rifier plan Supabase avant lancement massif**

**Stockage pr√©vu** :

| Table | Rows | Taille | Plan |
|-------|------|--------|------|
| `documents` | 930k | ~2 GB | ‚úÖ Free OK |
| `document_chunks` | 6M | ~20 GB | ‚ö†Ô∏è Pro requis |
| **Total** | 6.9M | ~22 GB | ‚ö†Ô∏è Pro 25 GB |

**V√©rification** :
```bash
# Dashboard Supabase ‚Üí Settings ‚Üí Usage
# V√©rifier: Database size < limite plan
```

---

### **3. Refresh vue mat√©rialis√©e toutes les 10 min (pas plus)**

**Configuration** :
```sql
-- pg_cron job (d√©j√† configur√©)
SELECT cron.schedule(
    'refresh_admin_metrics',
    '*/10 * * * *',  -- ‚úÖ Toutes les 10 min
    'SELECT refresh_admin_metrics_view();'
);
```

**Raison** :
- Moins de 10 min : CPU √©lev√©
- Plus de 10 min : M√©triques trop vieilles

---

## üîß BONNES PRATIQUES D√âPLOIEMENT

### **1. Backend : Rebuild sans cache si changement llama-cpp**

**Quand** :
- Changement `CMAKE_ARGS`
- Changement `n_ctx`
- Changement mod√®le GGUF

**Commande Render** :
```bash
# Dashboard Render ‚Üí Manual Deploy
# ‚úÖ Cocher "Clear build cache"
```

---

### **2. Frontend : npx vercel --prod apr√®s changement**

**Commande** :
```bash
cd ArchiReg-Front
npx vercel --prod --yes
```

**‚ö†Ô∏è Pas `vercel --prod`** (erreur "command not found")

---

### **3. Edge Functions : D√©ployer les 3 ensemble**

**Commande** :
```bash
supabase functions deploy admin-stats
supabase functions deploy cron-manager
supabase functions deploy system-tests
```

**Raison** : D√©pendances crois√©es (system-tests appelle admin-stats)

---

## üìä BONNES PRATIQUES MONITORING

### **1. V√©rifier CPU Supabase toutes les semaines**

**Dashboard** : https://supabase.com/dashboard/project/joozqsjbcwrqyeqepnev/reports

**Cibles** :
- ‚úÖ CPU : 12-15% (optimal)
- ‚ö†Ô∏è CPU : 20-30% (surveiller)
- ‚ùå CPU : >50% (optimiser queries)

---

### **2. Surveiller taux d'√©chec workers**

**Commande** :
```sql
SELECT 
    status,
    COUNT(*) as count,
    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM files_queue), 2) as percentage
FROM files_queue
GROUP BY status;
```

**Cibles** :
- ‚úÖ Failed : <0.1%
- ‚ö†Ô∏è Failed : 0.1-1%
- ‚ùå Failed : >1% (probl√®me √† investiguer)

---

### **3. Tester RAG r√©guli√®rement**

**Dashboard Admin** ‚Üí Actions ‚Üí Test RAG

**V√©rifications** :
- ‚úÖ Status 200
- ‚úÖ R√©sultats >0 (si embeddings charg√©s)
- ‚úÖ Latence <500ms (apr√®s warm-up)

---

## üîÑ BONNES PRATIQUES √âVOLUTION

### **1. Changement de mod√®le GGUF**

**Proc√©dure** :
```bash
# 1. T√©l√©charger nouveau mod√®le
wget https://url-du-modele.gguf -O WorkerLocal/models/nouveau-modele.gguf

# 2. Modifier config
# WorkerLocal/config/settings.py
model_filename: str = Field("nouveau-modele.gguf", ...)
vector_dim: int = Field(1024, ...)  # Si dimensions diff√©rentes

# 3. ‚ö†Ô∏è Si dimensions changent: REPARSER TOUT
# Vider tables + relancer workers
```

**‚ö†Ô∏è Important** : Mod√®le diff√©rent = embeddings incompatibles

---

### **2. Ajout nouveau type de chunk**

**Exemple** : Ajouter "alin√©a" comme type de chunk

**Modification** :
```python
# WorkerLocal Chunk/worker/chunk_batch.py
def _split_into_chunks(self, text: str, file_path: str):
    # STRAT√âGIE 5: Alin√©as
    alinea_pattern = r"(Alin√©a [0-9]+)"
    # ... code d√©coupage ...
```

**Test** :
```bash
python cli.py run --batch-size 10 --max-batches 1
# V√©rifier logs pour "chunking_version": "2.0-alineas"
```

---

### **3. Migration vers mod√®le plus grand (768 ‚Üí 1024 dims)**

**Proc√©dure compl√®te** :
```bash
# 1. Cr√©er nouvelles tables
CREATE TABLE documents_1024 (..., embedding VECTOR(1024));
CREATE TABLE document_chunks_1024 (..., embedding VECTOR(1024));

# 2. Modifier workers (vector_dim = 1024)

# 3. Lancer workers sur nouvelles tables

# 4. Une fois termin√©: Renommer tables
# documents_1024 ‚Üí documents
# document_chunks_1024 ‚Üí document_chunks

# 5. Mettre √† jour backend
```

**Dur√©e** : ~14-16h (re-g√©n√©ration compl√®te)

---

## üö® PI√àGES √Ä √âVITER

### **1. ‚ùå Ne PAS lancer 2 workers avec m√™me worker_id**

**Probl√®me** :
- M√©triques m√©lang√©es dans `ingestion_metrics`
- Impossible de tracer quel worker a fait quoi

**Solution** :
```python
# Toujours avoir worker_id UNIQUE par instance
worker_id: str = Field("workerlocal-ultra-turbo", ...)  # Worker 1
worker_id: str = Field("workerlocal-chunks-v2", ...)     # Worker 2
```

---

### **2. ‚ùå Ne PAS modifier RLS sur tables workers sans tester**

**Probl√®me** :
- RLS trop restrictives : Workers ne peuvent plus INSERT
- RLS trop permissives : Fuite de donn√©es

**Test apr√®s modification RLS** :
```bash
# Lancer worker en mode test
python cli.py run --batch-size 1 --max-batches 1

# V√©rifier logs:
# ‚úÖ "‚úÖ Document ins√©r√©: uuid-..."
# ‚ùå "403 Forbidden" ‚Üí RLS trop restrictive
```

---

### **3. ‚ùå Ne PAS oublier les index apr√®s cr√©ation table**

**Checklist nouvelle table avec embeddings** :
```sql
-- 1. Cr√©er table
CREATE TABLE ma_table (embedding VECTOR(768));

-- 2. ‚úÖ OBLIGATOIRE: Cr√©er index pgvector
CREATE INDEX idx_ma_table_embedding 
ON ma_table 
USING ivfflat (embedding vector_cosine_ops);

-- 3. ‚úÖ OBLIGATOIRE: Activer RLS
ALTER TABLE ma_table ENABLE ROW LEVEL SECURITY;

-- 4. ‚úÖ OBLIGATOIRE: Cr√©er policies
CREATE POLICY ma_table_select_policy ...
CREATE POLICY ma_table_insert_policy ...
```

---

### **4. ‚ùå Ne PAS ignorer les warnings llama.cpp**

**Warnings critiques** :
```bash
# ‚ùå CRITIQUE
"WARNING llama_context exceeds trained context length"
‚Üí n_ctx trop √©lev√© ‚Üí Qualit√© d√©grad√©e ‚Üí CORRIGER

# ‚ö†Ô∏è INFO
"ggml_backend_cuda_init: no CUDA devices found"
‚Üí Normal si CPU only ‚Üí Ignorer

# ‚ùå CRITIQUE
"SIGILL (rc=-4)"
‚Üí Instructions CPU non support√©es ‚Üí Recompiler sans AVX2
```

---

## üìñ COMMANDES UTILES

### **V√©rifier √©tat syst√®me complet**

```sql
-- M√©triques globales
SELECT 
    'files_queue' as table_name, COUNT(*) as rows FROM files_queue
UNION ALL
SELECT 'parsed_files', COUNT(*) FROM parsed_files
UNION ALL
SELECT 'documents', COUNT(*) FROM documents
UNION ALL
SELECT 'document_chunks', COUNT(*) FROM document_chunks;
```

### **V√©rifier index pgvector**

```sql
SELECT 
    schemaname, 
    tablename, 
    indexname, 
    indexdef 
FROM pg_indexes 
WHERE indexdef LIKE '%ivfflat%';
```

### **V√©rifier RLS**

```sql
SELECT tablename, rowsecurity 
FROM pg_tables 
WHERE schemaname = 'public' 
ORDER BY tablename;
```

---

## üéØ CHECKLIST AVANT MODIFICATION MAJEURE

### **Avant de modifier Workers** :

- [ ] Backup table `documents` et `document_chunks`
- [ ] Tester sur 10 fichiers (`--batch-size 10 --max-batches 1`)
- [ ] V√©rifier logs (z√©ro erreur)
- [ ] V√©rifier anti-duplication (doublons = succ√®s)
- [ ] Surveiller RAM/CPU pendant 5 min

### **Avant de modifier Backend** :

- [ ] Tester en local (`hypercorn backend.main:app`)
- [ ] V√©rifier n_ctx align√© avec mod√®le
- [ ] V√©rifier warm-up impl√©ment√©
- [ ] Tester endpoint RAG (`/api/v3/rag/search-legifrance?query=test`)
- [ ] Push sur branche `dev` d'abord (pas `main`)

### **Avant de modifier Tables Supabase** :

- [ ] Backup via SQL export
- [ ] Tester migration sur branche dev Supabase
- [ ] V√©rifier RLS apr√®s migration
- [ ] V√©rifier index pgvector cr√©√©s
- [ ] Tester workers apr√®s migration

---

## üéâ R√âSUM√â

**Points critiques** :
1. ‚úÖ n_ctx=512 (align√© mod√®le)
2. ‚úÖ Workers s√©quentiels (pas parall√®les sur m√™me source)
3. ‚úÖ Service_role pour workers
4. ‚úÖ Index pgvector obligatoires
5. ‚úÖ Pas de reparse inutile
6. ‚úÖ Warm-up backend
7. ‚úÖ AVX2/FMA d√©sactiv√©s (Render)
8. ‚úÖ Worker_mode READ_ONLY (backend)

**Bonnes pratiques** :
- ‚úÖ Batch 100, concurrence 50
- ‚úÖ Monitoring temps r√©el
- ‚úÖ Tests avant prod
- ‚úÖ RLS toujours activ√©es
- ‚úÖ Secrets jamais committ√©s

**Pi√®ges √©vit√©s** :
- ‚ùå Pas 2 workers m√™me worker_id
- ‚ùå Pas modifier RLS sans test
- ‚ùå Pas oublier index pgvector
- ‚ùå Pas ignorer warnings llama.cpp

---

**üìÖ Derni√®re mise √† jour** : 11 octobre 2025 22:55 UTC  
**‚úÖ Status** : GUIDE COMPLET - 100% VALID√â ‚úÖ

