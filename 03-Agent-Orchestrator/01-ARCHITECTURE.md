# ğŸ—ï¸ ARCHITECTURE BACKEND AGENT-ORCHESTRATOR

**Date** : 16 janvier 2025  
**Version** : 5.0.0  
**Framework** : FastAPI 0.115.5 + Python 3.12  
**Host** : Render.com (Starter Plan)

âš ï¸ **DOCUMENTATION V5.0 COMPLÃˆTE** : [Agent-Orchestrator/docs/01-ARCHITECTURE.md](../../../Agent-Orchestrator/docs/01-ARCHITECTURE.md) â­

---

## âš ï¸ CHANGEMENTS v5.0 (16/01/2025)

### **Code nettoyÃ©**
- âœ… 42 fichiers code mort supprimÃ©s
- âœ… 3 sanitizers fusionnÃ©s en 1 (OWASP 2025)
- âœ… Features enterprise ajoutÃ©es (ML security, Pydantic validator)

### **Migration Edge Functions**
- âŒ `api/v3/admin.py` â†’ ğŸŒ Edge Function `admin-stats`
- âŒ `api/v3/cron.py` â†’ ğŸŒ Edge Function `cron-manager`
- âŒ Tests (18) â†’ ğŸŒ Edge Function `system-tests`

### **Architecture mise Ã  jour**
- âœ… Python 3.12 (au lieu de 3.11)
- âœ… CI/CD security (audit CVE auto)
- âœ… Documentation complÃ¨te (5,100+ lignes)

---

## ğŸ¯ RESPONSABILITÃ‰S BACKEND

### **CE QU'IL FAIT** âœ…

```
1. API Chat Groq LLM
   â†“ Streaming SSE
2. Recherche RAG pgvector
   â†“ Retrieval embeddings GGUF
3. Health checks + System Tests
   â†“ Monitoring
4. Proxy Micro-service LÃ©gifrance
   â†“ ContrÃ´le scheduler
5. Admin API
   â†“ Metrics dashboard
```

**Fonctions clÃ©s** (Backend) :
1. **Chat LLM** : API Groq streaming SSE + historique Supabase
2. **RAG** : Recherche sÃ©mantique dans 312k documents pgvector
3. **Embeddings** : GÃ©nÃ©ration locale via GGUF (Solon-embeddings-large Q8_0)
4. **Projects** : CRUD projets ArchiReg
5. **Storage** : Upload fichiers Supabase
6. **Proxy** : ContrÃ´le Micro-service LÃ©gifrance (start/stop/mode)
7. **User Stats** : Analytics utilisateur
8. **Tests Backend** : 9 tests systÃ¨me directs
9. **Monitoring** : Structlog JSON + OpenTelemetry + Prometheus

**Fonctions migrÃ©es** ğŸŒ (Edge Functions Supabase) :
- ğŸŒ **Admin stats** : MÃ©triques dashboard (gain -99.7% latence)
- ğŸŒ **Cron manager** : Liste jobs pg_cron (read-only sÃ©curisÃ©)
- ğŸŒ **System tests** : 18 tests systÃ¨me (gain -59% latence)

### **CE QU'IL NE FAIT PAS** âŒ

- âŒ Collecte donnÃ©es (Micro-service LÃ©gifrance)
- âŒ Parsing/chunking documents (Workers locaux)
- âŒ Stockage fichiers (Supabase Storage direct)
- âŒ Auth utilisateurs (Supabase Auth)
- âŒ Admin dashboard (Edge Functions Supabase)

---

## ğŸ“Š SERVICES PRINCIPAUX

### **1. ChatService** (`api/v3/chat.py`)

**RÃ´le** : Gestion conversation LLM + streaming

```python
async def chat_streaming(
    user_message: str,
    conversation_id: str,
    user_id: str,
    system_prompt: str = None
) -> AsyncGenerator[str, None]:
    """
    Streaming Server-Sent Events (SSE)
    """
    # 1. Recherche RAG documents pertinents
    docs = await rag_service.search(user_message, limit=5)
    
    # 2. Construire contexte RAG
    context = build_context(docs)
    
    # 3. Appel Groq LLM
    async for chunk in groq_client.stream(
        model="llama-3.3-70b-versatile",
        messages=[
            {"role": "system", "content": context},
            {"role": "user", "content": user_message}
        ]
    ):
        yield chunk
    
    # 4. Sauvegarder dans Supabase
    await save_message(conversation_id, user_message, assistant_response)
```

**Endpoints** :
```http
POST /api/v3/chat/streaming    # Streaming SSE
POST /api/v3/chat/completions  # Legacy batch
GET  /api/v3/conversations      # Historique
```

---

### **2. RAGService** (`api/v3/rag.py`)

**RÃ´le** : Recherche sÃ©mantique pgvector

```python
class RAGService:
    async def search(
        self,
        query: str,
        limit: int = 10,
        similarity_threshold: float = 0.7
    ) -> List[Document]:
        """
        1. GÃ©nÃ©rer embedding requÃªte (GGUF local)
        2. Recherche cosine similarity pgvector
        3. Filtrer par seuil
        4. Retourner documents ordonnÃ©s
        """
        # Embedding query
        query_embedding = await self.embedding_service.generate(query)
        
        # Recherche vectorielle
        results = await self.db.execute(
            f"""
            SELECT 
                id, title, content,
                embedding <=> $1 AS distance
            FROM documents
            WHERE embedding <=> $1 < {1 - similarity_threshold}
            ORDER BY embedding <=> $1
            LIMIT {limit}
            """,
            query_embedding
        )
        
        return [Document(**row) for row in results]
```

**Performance** :
- âœ… <200ms avec index HNSW
- âœ… 312k vecteurs indexÃ©s (383 MB)
- âœ… Recall >95%

---

### **3. GGUFEmbeddingService** (`services/embeddings/gguf_service.py`)

**RÃ´le** : GÃ©nÃ©ration embeddings locaux

```python
class GGUFEmbeddingService:
    def __init__(self):
        self.model_name = "solon-embeddings-large-0.1-Q8_0.gguf"
        self.bucket_name = "ai-models"
        self.llm = None  # Lazy loading
    
    async def initialize(self):
        """
        Lazy loading : TÃ©lÃ©charge modÃ¨le depuis Supabase
        Seulement au premier appel embedding
        """
        if self.llm is None:
            local_path = await self._download_from_supabase()
            self.llm = Llama(
                model_path=local_path,
                embedding=True,
                n_ctx=512,
                n_threads=4,
                verbose=False
            )
    
    async def generate(self, text: str) -> List[float]:
        """GÃ©nÃ¨re embedding 768 dimensions"""
        await self.initialize()  # Lazy loading
        return self.llm.embed(text)
```

**ModÃ¨le utilisÃ©** :
- **Nom** : Solon-embeddings-large-0.1
- **Quantization** : Q8_0
- **Dimensions** : 768
- **Source** : Hugging Face â†’ Bucket Supabase `ai-models`

---

### **4. MicroserviceProxyService** (`api/v3/services_legifrance.py`)

**RÃ´le** : Proxy sÃ©curisÃ© vers Micro-service LÃ©gifrance

```python
class MicroserviceProxyService:
    async def start_collection(self):
        """POST /aspirage/start"""
        return await self._forward_request("POST", "/aspirage/start")
    
    async def stop_collection(self):
        """POST /aspirage/stop"""
        return await self._forward_request("POST", "/aspirage/stop")
    
    async def change_mode(self, mode: str):
        """POST /siphonnage/mode"""
        return await self._forward_request(
            "POST", 
            "/siphonnage/mode",
            json={"mode": mode}
        )
    
    async def get_status(self):
        """GET /aspirage/status"""
        return await self._forward_request("GET", "/aspirage/status")
```

**Endpoints** :
```http
POST /api/v3/legifrance/start        # DÃ©marre collecte
POST /api/v3/legifrance/stop         # ArrÃªte collecte
POST /api/v3/legifrance/mode         # Change MASSIVE â†” MAINTENANCE
GET  /api/v3/legifrance/status       # Ã‰tat scheduler
GET  /api/v3/legifrance/stats        # Stats collecte
```

---

### **5. SystemTestsService** (`api/v3/admin/system_tests.py`)

**RÃ´le** : Tests systÃ¨me hybrides (9 Backend + 18 Edge)

```python
class SystemTestsService:
    async def test_supabase(self) -> TestResult:
        """Test connexion DB"""
        try:
            result = await self.db.execute("SELECT 1")
            return TestResult(success=True, latency=...)
        except Exception as e:
            return TestResult(success=False, error=str(e))
    
    async def test_rag(self) -> TestResult:
        """Test RAG complet (embedding + search)"""
        query = "urbanisme PLU"
        docs = await self.rag_service.search(query, limit=5)
        return TestResult(
            success=len(docs) > 0,
            data={"docs_found": len(docs)}
        )
    
    async def test_groq_llm(self) -> TestResult:
        """Test Groq API"""
        response = await self.groq_client.chat(...)
        return TestResult(success=bool(response))
```

**9 Tests Backend** :
1. `test-supabase` : Connexion DB
2. `test-admin-api` : Edge Function admin-stats
3. `test-health-check` : Health endpoint
4. `test-pgvector` : Extension vector + HNSW
5. `test-materialized-view` : Vue admin_metrics_view
6. `test-cron-jobs` : pg_cron actif
7. `test-groq-llm` : API Groq
8. `test-simple` : Config backend
9. `run-unit-tests` : Tests unitaires Python

---

## ğŸ”„ FLUX RAG COMPLET

```mermaid
sequenceDiagram
    participant FE as Frontend
    participant BE as Backend
    participant GGUF as GGUF Service
    participant PG as pgvector
    participant GROQ as Groq API
    
    FE->>BE: POST /chat/streaming<br/>{message: "PLU..."}
    
    Note over BE: 1. Recherche RAG
    BE->>GGUF: generate_embedding(query)
    GGUF-->>BE: [0.1, 0.2, ..., 768 dims]
    
    BE->>PG: SELECT ... <=> embedding
    PG-->>BE: 5 documents pertinents
    
    Note over BE: 2. Construire contexte
    BE->>BE: build_context(docs)
    
    Note over BE: 3. Stream LLM
    BE->>GROQ: stream(context + query)
    loop Chunks streaming
        GROQ-->>BE: chunk
        BE-->>FE: SSE: data: {chunk}
    end
    
    Note over BE: 4. Sauvegarder
    BE->>PG: INSERT conversations/messages
```

---

## ğŸ“ STRUCTURE FICHIERS

```
Agent-Orchestrator/backend/
â”œâ”€â”€ main.py                      # Application FastAPI
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ startup.py              # Lifespan + init services
â”‚   â”œâ”€â”€ config.py               # Configuration env
â”‚   â”œâ”€â”€ security.py             # Auth JWT + admin
â”‚   â””â”€â”€ logging_config.py       # Structlog JSON
â”œâ”€â”€ api/
â”‚   â””â”€â”€ v3/
â”‚       â”œâ”€â”€ chat.py             # Chat streaming SSE
â”‚       â”œâ”€â”€ rag.py              # Recherche RAG
â”‚       â”œâ”€â”€ services_legifrance.py  # Proxy micro-service
â”‚       â””â”€â”€ admin/
â”‚           â”œâ”€â”€ system_tests.py      # Tests systÃ¨me
â”‚           â””â”€â”€ database_stats.py    # MÃ©triques DB (legacy)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ gguf_service.py     # Embeddings GGUF local
â”‚   â”œâ”€â”€ groq_service.py         # API Groq LLM
â”‚   â””â”€â”€ supabase_service.py     # Client Supabase
â”œâ”€â”€ db/
â”‚   â””â”€â”€ supabase_client.py      # Pool asyncpg + Supavisor
â””â”€â”€ middleware/
    â”œâ”€â”€ rate_limiting.py        # Protection DDoS
    â””â”€â”€ security.py             # Headers OWASP
```

---

## ğŸ” VARIABLES D'ENVIRONNEMENT

### **Supabase**
```bash
SUPABASE_URL=https://joozqsjbcwrqyeqepnev.supabase.co
SUPABASE_SERVICE_ROLE_KEY=xxx
DATABASE_URL=postgresql://postgres.joozqsjbcwrqyeqepnev:***@aws-0-eu-central-1.pooler.supabase.com:5432/postgres?sslmode=require&connect_timeout=10
```

### **Groq API**
```bash
GROQ_API_KEY=xxx
GROQ_MODEL=llama-3.3-70b-versatile
```

### **Micro-service**
```bash
MICROSERVICE_LEGIFRANCE_URL=https://micro-service-data-legifrance-piste.onrender.com
```

### **GGUF Embeddings**
```bash
GGUF_MODEL_NAME=solon-embeddings-large-0.1-Q8_0.gguf
GGUF_BUCKET_NAME=ai-models
EMBEDDING_DIM=768
```

### **Configuration**
```bash
ENVIRONMENT=production
LOG_LEVEL=INFO
ENABLE_CORS=true
```

---

## ğŸš€ DÃ‰PLOIEMENT RENDER

### **render.yaml**
```yaml
services:
  - type: web
    name: Agent-Orchestrateur-Backend
    runtime: python
    plan: starter
    buildCommand: pip install -r requirements.txt
    startCommand: hypercorn backend.main:app --bind 0.0.0.0:$PORT --workers 1 --worker-class uvloop --access-logfile - --log-level info
    healthCheckPath: /health
    autoDeploy: true
```

### **Hypercorn Configuration**
```python
# HTTP/2 + HTTPS
# Uvloop worker (performance)
# 1 worker (Starter Plan)
# Auto-restart on crash
```

---

## ğŸ¯ FLUX STARTUP

```
1. main.py - lifespan()
    â†“
2. Initialisation services
   - SupabaseService (pool asyncpg)
   - GGUFEmbeddingService (lazy loading)
   - GroqService
    â†“
3. Tests connexion
   - Health check DB
   - Verify pgvector extension
    â†“
4. âœ… Service prÃªt
   - API listening :10000
   - Health check OK
```

---

## ğŸ“Š OPTIMISATIONS CRITIQUES

### **1. Fix Asyncpg Pool** (21-FIX-POOL-ASYNCPG.md)

**ProblÃ¨me** : `{:shutdown, :client_termination}` sur RAG search

**Solution** :
```python
# Supavisor Session Mode (IPv4 compatible)
DATABASE_URL = "postgresql://...pooler.supabase.com:5432/...?sslmode=require&connect_timeout=10&application_name=backend"

# Pool asyncpg
pool = await asyncpg.create_pool(
    DATABASE_URL,
    min_size=2,
    max_size=10,
    command_timeout=60.0,
    server_settings={
        'application_name': 'backend-rag',
        'jit': 'off'
    }
)
```

**RÃ©sultat** :
- âœ… RAG fonctionne (0 â†’ 100% success)
- âœ… Latence <200ms
- âœ… Connexions stables

---

### **2. Fix Embeddings Incompatibles** (16-FIX-EMBEDDINGS-INCOMPATIBLES.md)

**ProblÃ¨me** : Workers (Windows AVX2) â‰  Backend (Linux no-AVX2)

**Solution** :
```python
# Forcer compilation source sans AVX2/FMA
pip install --no-binary=llama-cpp-python llama-cpp-python
```

**RÃ©sultat** :
- âœ… Embeddings identiques Workers â†” Backend
- âœ… RAG trouve documents (0 â†’ 312k)
- âœ… SimilaritÃ© cohÃ©rente

---

## ğŸ‰ RÃ©sumÃ© Architecture

**Backend ultra-optimisÃ©** :
- âœ… RAG pgvector performant (<200ms)
- âœ… Chat streaming SSE Groq
- âœ… Embeddings GGUF locaux
- âœ… Pool asyncpg stable
- âœ… Proxy micro-service sÃ©curisÃ©
- âœ… Tests hybrides (Backend + Edge)
- âœ… Hypercorn HTTP/2

**Architecture propre, rapide, rÃ©siliente !** ğŸš€

