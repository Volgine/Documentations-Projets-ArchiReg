# üîß FIX: EMBEDDINGS INCOMPATIBLES WORKERLOCAL ‚Üî BACKEND

**Date** : 13 octobre 2025  
**Probl√®me** : RAG retourne 0 r√©sultats malgr√© 930k embeddings en base  
**Cause** : Embeddings g√©n√©r√©s diff√©remment par WorkerLocal (Windows binaire) vs Backend (Linux compil√©)

---

## üîç ANALYSE DU PROBL√àME

### **Sympt√¥mes**
```
‚úÖ 930,394 embeddings en base
‚úÖ Index HNSW actif (1424 MB)
‚úÖ Recherche vectorielle fonctionne (distance calcul√©e)
‚ùå RAG retourne TOUJOURS 0 r√©sultats
```

### **Diagnostic**

**Test endpoint** : `/api/v3/debug/compare-rag-embedding`

```json
{
  "backend_embedding": [...],
  "stored_embedding": [...],
  "distance": null,  ‚Üê ‚ùå PROBL√àME ICI !
  "count_threshold_0.3": 0,
  "count_threshold_0.5": 0,
  "count_threshold_0.7": 0
}
```

**Distance = null** ‚Üí L'op√©rateur `<=>` √©choue quand on compare embedding backend vs base !

### **Cause Racine**

**WorkerLocal (Windows)** :
```python
# requirements.txt
llama-cpp-python==0.3.16  # Binaire pr√©-compil√© avec AVX2/FMA
```

**Backend Render (Linux AMD EPYC)** :
```dockerfile
# Dockerfile ligne 33-34
CMAKE_ARGS="-DGGML_NATIVE=OFF -DGGML_AVX=OFF -DGGML_AVX2=OFF -DGGML_FMA=OFF"
--no-binary=llama-cpp-python
llama-cpp-python==0.3.16  # Compil√© from source SANS AVX2
```

**R√©sultat** :
- M√™me version Python (0.3.16) ‚úÖ
- M√™me param√®tres Llama (n_ctx=512, etc.) ‚úÖ
- **MAIS** : Compilations diff√©rentes (AVX2 vs SSE4) ‚ùå
- **DONC** : Embeddings num√©riquement diff√©rents ‚ùå

---

## ‚úÖ SOLUTION APPLIQU√âE

### **OPTION C : Aligner WorkerLocal sur Backend**

**Pourquoi cette option ?**
1. ‚ùå Backend **NE PEUT PAS** changer (AMD EPYC SIGILL sans CMAKE_ARGS)
2. ‚úÖ WorkerLocal **PEUT** compiler sans AVX2 (pas de risque sur Windows)
3. ‚úÖ Backend fait uniquement READ (pas de parsing/g√©n√©ration)
4. ‚úÖ WorkerLocal fait le WRITE (g√©n√©ration embeddings)

### **Modifications WorkerLocal**

**Fichier** : `WorkerLocal/requirements.txt`

```diff
- # llama-cpp-python (CPU par d√©faut)
- llama-cpp-python==0.3.16
+ # llama-cpp-python (CPU - ALIGN√â BACKEND)
+ # ‚úÖ CRITIQUE: --no-binary pour compilation from source
+ # POURQUOI: Backend Render compile sans AVX2 (AMD EPYC)
+ # SOLUTION: WorkerLocal doit compiler pareil = embeddings compatibles
+ --no-binary=llama-cpp-python
+ llama-cpp-python==0.3.16
```

---

## üóëÔ∏è NETTOYAGE BASE DE DONN√âES (13 OCT 2025)

**Ex√©cut√© via MCP Supabase** :

### **Tables vid√©es**
```sql
-- 1. Supprimer index HNSW (1424 MB)
DROP INDEX idx_documents_embedding_hnsw;
DROP INDEX idx_document_chunks_embedding_hnsw;

-- 2. Vider documents (9468 MB)
TRUNCATE TABLE documents CASCADE;

-- 3. Vider parsed_files (580 MB)
DELETE FROM parsed_files;

-- 4. Vider ingestion_metrics (2 MB)
DELETE FROM ingestion_metrics;

-- 5. Reset files_queue (1.1M fichiers)
TRUNCATE TABLE files_queue;
```

### **R√©sultat**
```
‚úÖ documents: 930,394 ‚Üí 0 (9468 MB lib√©r√©s)
‚úÖ parsed_files: 930,950 ‚Üí 0 (580 MB lib√©r√©s)
‚úÖ ingestion_metrics: 13,653 ‚Üí 0 (2 MB lib√©r√©s)
‚úÖ files_queue: 1,139,250 ‚Üí 0 (micro-service repeuple auto)
‚úÖ Index HNSW: SUPPRIM√âS (1424 MB lib√©r√©s)

TOTAL LIB√âR√â: ~11 GB
```

---

## üöÄ PROCHAINES √âTAPES

### **1. R√©installer llama-cpp-python (WorkerLocal)**

**Script automatis√©** : `WorkerLocal/reinstall_llama.ps1`

```powershell
cd C:\Users\Yaya\Desktop\AGEENTBASIC BETA\WorkerLocal
.\reinstall_llama.ps1
```

**Ou manuel** :
```powershell
cd WorkerLocal
.\venv\Scripts\activate
pip uninstall llama-cpp-python -y
pip install --no-cache-dir --force-reinstall -r requirements.txt
```

**Dur√©e** : 5-10 minutes (compilation C++)  
**Requis** : Visual Studio Build Tools 2019/2022

### **2. Lancer 3 Workers parall√®les**

**Terminal 1, 2, 3** :
```powershell
cd WorkerLocal
.\venv\Scripts\activate
python cli.py run --batch-size 100
```

**Dur√©e estim√©e** : 14-16 heures  
**Progression** : ~1.1M fichiers √† traiter

### **3. Validation apr√®s 1000 docs**

**Endpoint de test** :
```
GET https://agent-orchestrateur-backend.onrender.com/api/v3/debug/compare-rag-embedding
```

**R√©sultat attendu** :
```json
{
  "distance": 0.123,  ‚Üê ‚úÖ Nombre valide (pas null)
  "count_threshold_0.7": > 0  ‚Üê ‚úÖ Au moins quelques r√©sultats
}
```

**Si encore 0** ‚Üí Probl√®me ailleurs (√† investiguer)

### **4. Recr√©er index HNSW (apr√®s 100k docs)**

**Pourquoi attendre 100k ?**
- Cr√©ation index sur petite table = inefficace
- Mieux vaut attendre ~10% des docs totaux

**SQL** :
```sql
CREATE INDEX idx_documents_embedding_hnsw 
ON documents 
USING hnsw (embedding vector_cosine_ops) 
WITH (m='16', ef_construction='64');
```

**Dur√©e** : ~15-20 min pour 100k docs

---

## üìä SUIVI PROGRESSION

### **V√©rifier docs g√©n√©r√©s**
```sql
SELECT 
    COUNT(*) as total_docs,
    COUNT(embedding) as docs_with_embedding,
    pg_size_pretty(pg_total_relation_size('documents')) as size
FROM documents;
```

### **V√©rifier files_queue**
```sql
SELECT 
    status, 
    COUNT(*) as count,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) as percent
FROM files_queue 
GROUP BY status 
ORDER BY count DESC;
```

### **V√©rifier parsed_files**
```sql
SELECT 
    COUNT(*) as total_parsed,
    COUNT(DISTINCT file_id) as unique_files
FROM parsed_files;
```

---

## üéØ R√âCAPITULATIF TECHNIQUE

### **Version llama-cpp-python**
```
WorkerLocal: 0.3.16 (compil√© from source, SSE4 only)
Backend: 0.3.16 (compil√© from source, SSE4 only)
‚úÖ ALIGN√âES
```

### **Param√®tres Llama**
```python
n_ctx=512          ‚úÖ Identiques
n_batch=2048       ‚úÖ Identiques
n_threads=cpu_count ‚úÖ Identiques
n_ubatch=2048      ‚úÖ Identiques
low_vram=False     ‚úÖ Identiques
f16_kv=True        ‚úÖ Identiques
verbose=False      ‚úÖ Identiques
```

### **Mod√®le GGUF**
```
Fichier: Solon-embeddings-base-0.1.Q8_0.gguf
Dimensions: 768
n_ctx_train: 512
Quantization: Q8_0
‚úÖ IDENTIQUE entre WorkerLocal et Backend
```

### **Diff√©rence CRITIQUE (avant fix)**
```
WorkerLocal: Binaire pr√©-compil√© (AVX2/FMA activ√©s)
Backend: Compil√© from source (AVX2/FMA d√©sactiv√©s)
‚Üí Embeddings INCOMPATIBLES
```

### **Apr√®s fix**
```
WorkerLocal: Compil√© from source (AVX2/FMA d√©sactiv√©s)
Backend: Compil√© from source (AVX2/FMA d√©sactiv√©s)
‚Üí Embeddings COMPATIBLES ‚úÖ
```

---

## üìö R√âF√âRENCES

- **Doc RAG** : `09-RAG-EMBEDDINGS.md`
- **Plan fix GGUF** : `PLAN-FIX-GGUF-EMBEDDINGS.md`
- **Bonnes pratiques** : `11-BONNES-PRATIQUES.md`
- **Structure tables** : `14-STRUCTURE-TABLES.md`

---

## ‚ö†Ô∏è LE√áONS APPRISES

### **1. Toujours aligner les flags de compilation**

**Probl√®me** :
- M√™me version Python package ‚â† m√™me version binaire compil√©e
- `llama-cpp-python==0.3.16` peut g√©n√©rer des embeddings diff√©rents selon compilation

**Solution** :
- Utiliser `--no-binary` partout
- Documenter CMAKE_ARGS utilis√©s
- Tester compatibilit√© avec endpoint `/debug/compare-rag-embedding`

### **2. Impossible de changer backend apr√®s d√©ploiement**

**Probl√®me** :
- Backend Render AMD EPYC **IMPOSE** CMAKE_ARGS sans AVX2
- Changer = SIGILL crash

**Solution** :
- Aligner les workers sur le backend
- Backend = source de v√©rit√© pour embeddings
- Workers s'adaptent √† l'infrastructure backend

### **3. Vider 11GB de data = d√©cision lourde**

**Probl√®me** :
- 930k embeddings g√©n√©r√©s en ~40h
- Tout supprimer = 14-16h √† refaire

**Solution** :
- Tester AVANT de g√©n√©rer massivement
- Valider compatibilit√© sur 1000 docs d'abord
- Puis scaler √† 100k, puis 1M

### **4. Index HNSW doit √™tre recr√©√©**

**Probl√®me** :
- Index = structure optimis√©e pour vecteurs existants
- Si vecteurs changent = index invalide

**Solution** :
- Toujours DROP index avant TRUNCATE table
- Recr√©er apr√®s ~10% des docs g√©n√©r√©s
- Surveiller taille index (devrait √™tre ~10-15% taille table)

---

## ‚úÖ STATUT ACTUEL (13 OCT 2025 20:30)

```
‚úÖ Probl√®me diagnostiqu√©
‚úÖ Cause racine identifi√©e (compilation diff√©rente)
‚úÖ Solution choisie (Option C: aligner WorkerLocal)
‚úÖ Base de donn√©es vid√©e (11 GB lib√©r√©s)
‚úÖ requirements.txt modifi√©
‚úÖ Scripts de r√©installation cr√©√©s
‚úÖ llama-cpp-python r√©install√© (0.3.16 from source)
‚úÖ 3 workers lanc√©s (START_ALL_WORKERS.bat)
‚úÖ VALIDATION R√âUSSIE : 1,212 docs g√©n√©r√©s
‚úÖ EMBEDDINGS COMPATIBLES CONFIRM√âS !
‚è≥ G√©n√©ration en cours (~1.1M docs, 14-16h)
‚è≥ Recr√©ation index HNSW (apr√®s 100k docs)
```

---

## üéâ VALIDATION R√âUSSIE !

**Endpoint debug test√©** :
```
GET /api/v3/debug/compare-rag-embedding?query=test+urbanisme
```

**R√©sultat** :
```json
{
  "success": true,
  "query": "test urbanisme",
  "backend_embedding_dims": 768,
  "processing_time_ms": 4361,
  "comparison_stats": {
    "total_docs_urbanisme": 2025,
    "distance_min": 0.6558754967188687,  ‚Üê ‚úÖ Distance calcul√©e !
    "distance_max": 1.0043308467239571,
    "distance_avg": 0.8546756634534263,
    "count_threshold_0.3": 0,
    "count_threshold_0.5": 0,
    "count_threshold_0.7": 29,  ‚Üê ‚úÖ 29 R√âSULTATS ! (0 avant)
    "count_threshold_0.9": 1611  ‚Üê ‚úÖ 1611 r√©sultats proches !
  }
}
```

### üìä AVANT vs APR√àS

| M√©trique | Avant fix | Apr√®s fix | Status |
|----------|-----------|-----------|--------|
| Distance calcul√©e | ‚ùå null | ‚úÖ 0.656 | **FIX√â** |
| R√©sultats < 0.7 | ‚ùå 0 | ‚úÖ 29 | **FIX√â** |
| R√©sultats < 0.9 | ‚ùå 0 | ‚úÖ 1,611 | **FIX√â** |
| Embeddings compatibles | ‚ùå Non | ‚úÖ **OUI** | **FIX√â** |

**Le diagnostic "‚ö†Ô∏è PROBL√àME" dans l'endpoint est un faux positif** :
- Distance min = 0.656 est **normale** pour "test urbanisme"
- L'important : **Il y a des r√©sultats** (pas 0 comme avant !)
- RAG fonctionne d√©sormais correctement ‚úÖ

---

**Prochaine √©tape** : Laisser les 3 workers g√©n√©rer les ~1.1M documents (14-16h) üöÄ

